{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b010703-6a13-4f1b-b201-3863dab69e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165d7d5-bc3f-45be-ba07-87848893e5c3",
   "metadata": {},
   "source": [
    "# Convert BVH to CSV Files\n",
    "\n",
    "Hacky code to pull out just the local acceleration data across joints / frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b33467b-66c6-471d-9c1d-b6cbd106b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't need to rerun - used to create dsv_data\n",
    "def convert_file(file_in, file_out):\n",
    "    file = open(file_in, \"r\")\n",
    "    full_data = file.readlines()\n",
    "    i = full_data.index(\"MOTION\\n\")\n",
    "    frames = int(full_data[i+1].strip().replace(\"Frames: \", \"\"))\n",
    "    frame_time = float(full_data[i+2].strip().replace(\"Frame Time: \", \"\"))\n",
    "    # print(frames, frame_time)\n",
    "\n",
    "    pos_data = [] # frame [ 83 joints [xpos, ypos, zpos, zrot, xrot, yrot]]]\n",
    "    for frame in full_data[i+3: ]:\n",
    "        pos_data.append( [float(x) for x in frame.split()])\n",
    "    \n",
    "    # take the derivative to get acceleration\n",
    "    pos_data = np.array(pos_data)\n",
    "    v_data = np.diff(pos_data, 1, 0)\n",
    "    acc_data = np.diff(pos_data, 2, 0)\n",
    "    \n",
    "    # How much does taking the derivative reduce the amount of non zero data?\n",
    "    total_size = np.size(pos_data)\n",
    "    # print(total_size , round(np.count_nonzero(pos_data)/total_size*100,4), round(np.count_nonzero(acc_data)/total_size*100, 4))\n",
    "    # ~ 70 -> 20%\n",
    "    \n",
    "    # cut out the first ~5 seconds on each side of the take to remove weird artifacts\n",
    "    acc_data = acc_data[500: -500]\n",
    "    \n",
    "    np.savetxt(file_out, acc_data, delimiter=',', fmt='%d')\n",
    "    # TODO - is there a better way to store this that capitalizes on the sparsity?\n",
    "\n",
    "    file.close()\n",
    "    return len(acc_data), frame_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb23c92-42cf-4238-b801-df4cdf7bbfc4",
   "metadata": {},
   "source": [
    "Go through each pair of bvh files and convert to csv with new naming convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c593e768-4174-45a1-9b3b-9fadd88b2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't need to rerun - used to create dsv_data\n",
    "data_dir = \"mocap_data\"\n",
    "\n",
    "frames = []\n",
    "frame_length = []\n",
    "\n",
    "# iterate through the session directories\n",
    "for session_dir in os.listdir(data_dir):\n",
    "    if not session_dir.startswith(\"session\"):\n",
    "        continue\n",
    "    session_path = os.path.join(data_dir, session_dir)\n",
    "    for take_dir in os.listdir(session_path):\n",
    "        if not take_dir.startswith(\"take\"):\n",
    "            continue\n",
    "        take_path = os.path.join(session_path, take_dir)\n",
    "        file_a, file_b =  [x for x in os.listdir(take_path) if \".bvh\" in x]\n",
    "        person_a = file_a.replace(take_dir + \"_hasFingers_\", \"\").replace(\"_scale_local.bvh\", \"\")\n",
    "        person_b = file_b.replace(take_dir + \"_hasFingers_\", \"\").replace(\"_scale_local.bvh\", \"\")\n",
    "        new_a = \"csv_data/\" + person_a + \"_\" + person_b + \"_\" + session_dir.replace(\"ession\", \"\") + take_dir.replace(\"ake\", \"\") + '.csv'\n",
    "        new_b = \"csv_data/\" + person_b + \"_\" + person_a + \"_\" + session_dir.replace(\"ession\", \"\") + take_dir.replace(\"ake\", \"\") + '.csv'\n",
    "        f, f_len = convert_file(os.path.join(take_path, file_a), new_a)\n",
    "        frames.append(f)\n",
    "        frame_length.append(f_len)\n",
    "        f, f_len\n",
    "        convert_file(os.path.join(take_path, file_b), new_b)\n",
    "        frames.append(f)\n",
    "        frame_length.append(f_len)\n",
    "        \n",
    "print(frames[0])\n",
    "\n",
    "# Do we need to chop up any of our data?\n",
    "print(np.min(frames), np.max(frames)/np.min(frames)) # 5226 min length of motion\n",
    "      \n",
    "# Are all frames captured at the same frame rate?\n",
    "print(frame_length[0], len([x for x in frame_length if x!= frame_length[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1aafda-579d-47ff-ab62-87c6f07c77cb",
   "metadata": {},
   "source": [
    "# Load in CSV to create data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ae96c1f-f243-43ca-bc3f-a77e80dfcb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "l = 5226 #56 files\n",
    "speaker = []\n",
    "audience =  []\n",
    "\n",
    "# format data so that each column is a  // WHY IS THIS SOOOOO SLOW?\n",
    "for file in [x for x in os.listdir(\"csv_data\") if \".csv\" in x]:\n",
    "    print(file)\n",
    "    d = np.loadtxt(os.path.join(\"csv_data\", file), delimiter=',')\n",
    "    for i in range(d.shape[0]//l): # use numpy reshape instead??\n",
    "        chunk = np.array(d[i*l: (i+1)*l]).flatten()\n",
    "        speaker.append(info[0])\n",
    "        audience.append(info[1])\n",
    "        if (data is None):\n",
    "            data = [chunk]\n",
    "        else:\n",
    "            data.append(chunk)\n",
    "            \n",
    "data = np.transpose(np.array(data)) # each column is a series of accelerations from within a take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0c09a27-5455-49b9-8c4d-7a503260ca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2602548, 526)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "np.savetxt(\"matrix_data.csv\", data, delimiter=',', fmt='%d')\n",
    "# TODO: This is a sparse matrix so we can store this even more efficiently - scipy might do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09915c3c-572a-4b86-87bb-bd5c599e8452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp38-cp38-macosx_10_9_x86_64.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /Users/anna/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/anna/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from scikit-learn) (1.23.2)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29575a2c-7e05-473f-bcc2-220676f3587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7069aa3-40ab-4597-b1a3-4826b5a698f8",
   "metadata": {},
   "source": [
    "## Is there any other preprocessing that we need to do - normalization or otherwise?\n",
    "\n",
    "## TODO, SVD -> PCA, Or direct PCA to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c361ff06-b917-4815-bf21-fa5aa08c84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce down to subset of features\n",
    "pca = PCA(n_components=2)\n",
    "pca_feats = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4388660-d412-4d0c-98ef-be61788bae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOt working yet PCA fit takes too long. Code from demo  - https://www.jcchouinard.com/pca-with-python/#PCA_Examples_From_This_Tutorial\n",
    "\n",
    "# Create dataframe\n",
    "pca_df = pd.DataFrame(\n",
    "    data=pca_features, \n",
    "    columns=['PC1', 'PC2'])\n",
    " \n",
    "# map target names to PCA features   \n",
    "target_names = {\n",
    "    0:'setosa',\n",
    "    1:'versicolor', \n",
    "    2:'virginica'\n",
    "}\n",
    " \n",
    "pca_df['target'] = y\n",
    "pca_df['target'] = pca_df['target'].map(target_names)\n",
    " \n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8430b-ef8b-44d5-b48e-53dc222870f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    " \n",
    "sns.lmplot(\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    data=pca_df, \n",
    "    hue='target', \n",
    "    fit_reg=False, \n",
    "    legend=True\n",
    "    )\n",
    " \n",
    "plt.title('2D PCA Graph')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
